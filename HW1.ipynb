{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание №1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве данных я взяла отзывы с сайта [Фламп](https://moscow.flamp.ru/), а именно [отзывы на кофейни](https://moscow.flamp.ru/metarubric/kofejni). Здесь можно фильтровать отзывы по окраске (\"положительные\", \"отрицательные\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "morph = MorphAnalyzer()\n",
    "stopwords = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Парсинг данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем два массива для положительных и отрицательных отзывов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_reviews = []\n",
    "negative_reviews = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Парсим сайт с отзывами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_from_url(href: str) -> BeautifulSoup:\n",
    "    \"\"\"\n",
    "    Функция, которая парсит страницу с кофейнями\n",
    "    :param href: строка со ссылкой\n",
    "    :return: распарсенная страница\n",
    "    \"\"\"\n",
    "    response = requests.get(href)\n",
    "    html_content = response.text\n",
    "    return BeautifulSoup(html_content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "cafes = []\n",
    "for page in range(1, 100):\n",
    "    main_link = f\"https://moscow.flamp.ru/metarubric/kofejni?page={page}\"\n",
    "    soup = get_from_url(main_link)\n",
    "    cafes.extend(soup.find_all('a', {'class': 'card__link'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews(href: str, rating: str = 'positive') -> list:\n",
    "    \"\"\"\n",
    "    Функция, которая парсит страницу с отзывами\n",
    "    :param href: строка со ссылкой\n",
    "    :param rating: строка, по которой фильтруются отзывы {'positive', 'negative'}\n",
    "    :return: список отзывов\n",
    "    \"\"\"\n",
    "    soup = get_from_url(link + f'?rating={rating}')\n",
    "    reviews = soup.find_all('p', {'class': 't-rich-text__p'})\n",
    "    return [review.get_text().strip() for review in reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cafe in cafes:\n",
    "    link = 'https:'+cafe['href']\n",
    "    positive_reviews.extend(get_reviews(link, 'positive'))\n",
    "    negative_reviews.extend(get_reviews(link, 'negative'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, сколько отзывов мы достали и хватит ли нам их"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6518, 6034)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(positive_reviews), len(negative_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В целом достаточно, но здесь имеются \"лишние\" отзывы. Например, первый отзыв это нераскрывшийся следующий, а между ними встряла кнопка 'Показать целиком':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['31 декабря в 10 утра зашли в кафе на ул. Арбат, 19. Быстро обслужили, спасибо. Далее выбрали место у окна - планировали посидеть долго, полюбоваться праздничной улицей. Столик не убран, попросила \"Уберите, пожалуйста\". Начался театр двух актеров. Чернявый юноша, который делал кофе, посмотрел на меня, что-то обсудил со светловолосой дамой в черной...',\n",
       " 'Показать целиком',\n",
       " '31 декабря в 10 утра зашли в кафе на ул. Арбат, 19. Быстро обслужили, спасибо. Далее выбрали место у окна - планировали посидеть долго, полюбоваться праздничной улицей. Столик не убран, попросила \"Уберите, пожалуйста\". Начался театр двух актеров. Чернявый юноша, который делал кофе, посмотрел на меня, что-то обсудил со светловолосой дамой в черной шляпе (не продавец, видимо, менеджер) и сделал вид, что не услышал. Я просто смотрела на него, парень понял, что придется убрать. В кафе на тот момент было 4 посетителя, устать персонал не успел. Пара скрылась за дверью для персонала, по очереди выглядывала оттуда, парень подошел и вылил на стол, на кресло и на пол оставшийся напиток. Затем вернулся с тряпкой, протер стол, пошел за шваброй. Вышел и показал швабру напарнице, та потрогала швабру руками и затем поправляла этими же руками что-то на витрине (менеджер?). Парень справился с лужей на полу и смертельно уставший пошел курить с напарницей (в черной шляпе). Оба потом стояли и обсуждали нас, глядя в окно. Процедура уборки заняла 25 минут. Наверняка было бы быстрее, если бы я начала качать права. Но мне было любопытно, появиться у сотрудников понимание, что они на работе, и что их зп - это деньги, которые приносят клиенты. Работу этих сотрудников оцениваю -10. Кофе за время уборки остыл, поэтому уже был невкусный, оценить не смогу. Столько людей, кому нужна работа, гоните в шею эту парочку, больше не захочется зайти в это кафе.']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_reviews[2:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для этого почистим отзывы и отберем только часть из них, чтобы уравнять количество"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(reviews: list) -> list:\n",
    "    \"\"\"\n",
    "    Функция, которая убирает лишние отзывы\n",
    "    :param reviews: список отзывов\n",
    "    :return: список отзывов\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    while i < len(reviews):\n",
    "        if reviews[i] == 'Показать целиком':\n",
    "            reviews.pop(i)\n",
    "            reviews.pop(i-1)\n",
    "            i -= 1\n",
    "        else:\n",
    "            i += 1\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_reviews = remove_noise(positive_reviews)\n",
    "negative_reviews = remove_noise(negative_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5140, 4704)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(positive_reviews), len(negative_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_reviews = positive_reviews[:4700]\n",
    "negative_reviews = negative_reviews[:4700]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично! Мы собрали отзывы, теперь можно с ними работать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Классификация отзывов с помощью множеств"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала разделим выборку на трейн и тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(positive_reviews)\n",
    "random.shuffle(negative_reviews)\n",
    "train_positive, test_positive = positive_reviews[:3700], positive_reviews[3700:]\n",
    "train_negative, test_negative = negative_reviews[:3700], negative_reviews[3700:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь нужно токенизировать отзывы и собрать леммы для того, чтобы составить словари положительных и отрицательных слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text: str) -> list:\n",
    "    \"\"\"\n",
    "    Функция, которая токенизирует строку текста\n",
    "    :param text: строка текста\n",
    "    :return: список токенов\n",
    "    \"\"\"\n",
    "    return [morph.parse(word)[0].normal_form for word in word_tokenize(text.lower()) if (re.search(r\"[^a-zа-я ]\", word) is None) and word not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_reviews(reviews: list) -> list:\n",
    "    \"\"\"\n",
    "    Функция, которая сщбирает леммы из отзывов\n",
    "    :param reviews: список отзывов\n",
    "    :return: список лемм\n",
    "    \"\"\"\n",
    "    lemmas = []\n",
    "    for review in reviews:\n",
    "        lemmas.extend(tokenizer(review))\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_positive_lemmas = tokenize_reviews(train_positive)\n",
    "train_negative_lemmas = tokenize_reviews(train_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выберем наиболее частотные слова для каждого класса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words = Counter(train_positive_lemmas)\n",
    "negative_words = Counter(train_negative_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words_freq = [k for k in positive_words if positive_words[k] > 5]\n",
    "negative_words_freq = [k for k in negative_words if negative_words[k] > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1520, 1621)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(positive_words_freq), len(negative_words_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем общее множество слов в отдельный массив и уберем слова из этого множества из словарей с положительными и отрицательными словами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "both = []\n",
    "for word in positive_words_freq:\n",
    "    if word in negative_words_freq:\n",
    "        both.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1291"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words_freq = [word for word in positive_words_freq if word not in both]\n",
    "negative_words_freq = [word for word in negative_words_freq if word not in both]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(229, 330)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(positive_words_freq), len(negative_words_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь напишем функцию для классификации и функцию с метрикой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_rating(review: list) -> str:\n",
    "    \"\"\"\n",
    "    Функция, которая классифицирует отзыв по наличи в нем слов из множеств положительных и отрицательных слов\n",
    "    :param reviews: список отзывов\n",
    "    :return: строка, которая говорит, к какому классу мы отнесли отзыв {'positive', 'negative', 'cannot define'}\n",
    "    \"\"\"\n",
    "    positive = 0\n",
    "    negative = 0\n",
    "    for word in review:\n",
    "        if word in positive_words_freq:\n",
    "            positive += 1\n",
    "        elif word in negative_words_freq:\n",
    "            negative += 1\n",
    "    if positive > negative:\n",
    "        return 'positive'\n",
    "    elif negative > positive:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'cannot define'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_accuracy(positive, negative):\n",
    "    posititve_lemmas = [tokenizer(review) for review in positive]\n",
    "    negative_lemmas = [tokenizer(review) for review in negative]\n",
    "    positive_ratings = [check_rating(review) for review in posititve_lemmas]\n",
    "    negative_ratings = [check_rating(review) for review in negative_lemmas]\n",
    "    print(f\"accuracy = {(positive_ratings.count('positive') + negative_ratings.count('negative')) / (len(positive_ratings) + len(negative_ratings))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим качество на трейне и на тесте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.2875675675675676\n"
     ]
    }
   ],
   "source": [
    "count_accuracy(train_positive, train_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.2075\n"
     ]
    }
   ],
   "source": [
    "count_accuracy(test_positive, test_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Улучшения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, классификатор оказался очень плохим даже на трейне.\n",
    "1. Мы никак не учитывали частоты. Мы просто создали два множества слов, определив порог попадания, но какое-то слово могло попасть в оба множества, при этом его частотность для положительного класса гораздо выше, чем для отрицательного, например, но мы не считаем это слово как индикатор тональности, потому что оно попало в оба класса.\n",
    "2. Лучше здесь, конечно, использовать ML. Обучить классификатор (у нас просто бинарная классификация) на bag-of-words/tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
